# -*- coding: utf-8 -*-
"""Testing for Audio Denoising.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19-uYHjl74TrTo4JkKHA8aOfQLoLFI4vo
"""

import numpy as np

import IPython.display as ipd
import librosa
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
import tensorflow as tf

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')
#!cd 'drive/My Drive/RL_Code'
# %cd drive/My Drive/audio_files
import numpy as np
a = np.load('rounded_inputs.npy',allow_pickle=True)

# load data
a_files = ['CantinaBand3.wav', 'StarWars3.wav', 'gettysburg.wav', 'taunt.wav', 'example1.mp3', 'preamble.wav']
# a_files = ['136.wav', '137.wav']
audio, samplerate = librosa.load(a_files[2])
longer_audios = []
# for i in range(500):
#   l = len(a[i])
#   if l > 300000:
#     print(i, len(a[i]))
#     longer_audios.append(i)

# audio = a[longer_audios[4]]

# Flatten into one large array and add noise
flattened = audio[:int(len(audio)-(len(audio)%1000))]
noise = np.random.normal(0, 0.01, (int(flattened.shape[0]),))
noisy_data = noise + flattened

display(ipd.Audio(noisy_data, rate=samplerate))

# Reshape inputs and outputs for training
X_shaped = np.reshape(noisy_data, (int(flattened.shape[0]/1000), 1, 1000))
Y_shaped = np.reshape(flattened, (int(flattened.shape[0]/1000), 1, 1000))

# Split train and test data
X_train, X_test, y_train, y_test = train_test_split(X_shaped, Y_shaped, test_size=0.10, random_state=42)

# plt.plot(flattened)
# plt.show()
# plt.plot(noisy_data)
model = Sequential()
model.add(LSTM((1000), input_shape=(1, 1000), return_sequences=True, activation='tanh'))
model.add(LSTM((1000), return_sequences=True, activation='tanh'))
#model.add(LSTM((1000), return_sequences=True, activation='tanh'))
model.compile(loss='mean_squared_error', optimizer='adam', metrics=["accuracy"])
model.summary()
history = model.fit(X_train, y_train, epochs=1000, batch_size=32, verbose=2)

history1 = model.fit(X_train, y_train, epochs=300, batch_size=32, verbose=2)

flattened = audio[:int(len(audio)-(len(audio)%1000))]
noise = np.random.normal(0, 0.04, (int(flattened.shape[0]),))
noisy_data = noise + flattened

# Reshape inputs and outputs for training
X_shaped = np.reshape(noisy_data, (int(flattened.shape[0]/1000), 1, 1000))
Y_shaped = np.reshape(flattened, (int(flattened.shape[0]/1000), 1, 1000))

predict = model.predict(model.predict(X_shaped))
shaped_out = np.reshape(predict, (len(flattened)))
display(ipd.Audio(noisy_data, rate=samplerate))
display(ipd.Audio(shaped_out, rate=samplerate))
plt.plot(noisy_data)
plt.plot(shaped_out)
plt.show()
# plt.plot(history.history['accuracy'])
# plt.show()
plt.plot(history.history['loss'])

history2 = model.fit(X_shaped, Y_shaped, epochs=300, batch_size=32, verbose=2)